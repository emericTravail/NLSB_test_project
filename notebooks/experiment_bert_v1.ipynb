{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f0e921ee",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "f0e921ee",
        "outputId": "fa3e7ca6-fb29-428e-cac6-b9eabf62671c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 21 16:43:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8             14W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from datasets import Dataset\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "n5PofM31qQwT"
      },
      "id": "n5PofM31qQwT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "KQoRCYSqrEj4"
      },
      "id": "KQoRCYSqrEj4"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Module to transform data to be consumable by model\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from transformers import BertTokenizerFast, AutoTokenizer\n",
        "\n",
        "\n",
        "\n",
        "class DatabaseToBertDataset():\n",
        "    def __init__(self, model_name):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name) # (\"bert-base-multilingual-cased\")\n",
        "        self.tokenizerChunkLen = self.tokenizer.model_max_length\n",
        "\n",
        "    def _tokenize(self, df: str) -> pd.DataFrame:\n",
        "        \"\"\"Tokenizer function\"\"\"\n",
        "        tokenized = self.tokenizer(\n",
        "            df[\"email\"].to_list(),\n",
        "            df[\"bill\"].to_list(),\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            stride=128,                        # overlap between chunks\n",
        "            return_overflowing_tokens=True,    # keep extra chunks\n",
        "            return_offsets_mapping=True,       # optional: track positions in original text\n",
        "            return_tensors=\"pt\"                # PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # print(type(tokenized))\n",
        "        # print(tokenized['input_ids'].shape)\n",
        "        # print(tokenized['token_type_ids'].shape)\n",
        "        # print(tokenized['attention_mask'].shape)\n",
        "        # print(tokenized['offset_mapping'].shape)\n",
        "        # print(tokenized['overflow_to_sample_mapping'].shape)\n",
        "        # input('MMMM')\n",
        "\n",
        "        return tokenized\n",
        "\n",
        "    def _encode_labels(self, df: pd.DataFrame) -> tuple[pd.DataFrame, np.ndarray]:\n",
        "        \"\"\"Encode labels\"\"\"\n",
        "\n",
        "        # Get unique labels from labels description\n",
        "        with open('labels.json', 'r') as file:\n",
        "            labels = json.load(file)['etiquettes']\n",
        "        labelIds = [label['id'] for label in labels]\n",
        "\n",
        "        # Format original labels\n",
        "        df['labels'] = df['labels'].apply(\n",
        "            lambda x: x.split('|') if isinstance(x, str) else []\n",
        "        )\n",
        "\n",
        "        # Encode\n",
        "        mlb = MultiLabelBinarizer(classes=labelIds)\n",
        "        encoded = mlb.fit_transform(df['labels'])\n",
        "        df = pd.concat(\n",
        "            [df, pd.DataFrame(encoded, columns=mlb.classes_)],\n",
        "            axis=1\n",
        "        )\n",
        "        df = df.drop(columns='labels')\n",
        "\n",
        "        return df, mlb.classes_\n",
        "\n",
        "\n",
        "    def execute(self, df : pd.DataFrame) -> tuple[dict[torch.Tensor], np.ndarray]:\n",
        "        \"\"\"\n",
        "        Transform from database to dataset consumable by model\n",
        "        \"\"\"\n",
        "\n",
        "        # Tokenize ('input_ids' 'attention_mask''token_type_ids' 'overflow_to_sample_mapping')\n",
        "        data = self._tokenize(df)\n",
        "\n",
        "        labelCols = None\n",
        "        if 'labels' in df.columns:\n",
        "            df, labelCols = self._encode_labels(df)\n",
        "\n",
        "            labels_tensor = torch.tensor(df[labelCols].to_numpy())\n",
        "            expanded_labels = labels_tensor[data['overflow_to_sample_mapping']]\n",
        "\n",
        "            data['labels'] = expanded_labels\n",
        "\n",
        "        return data, labelCols"
      ],
      "metadata": {
        "id": "I8x9eo3ZrNhv"
      },
      "id": "I8x9eo3ZrNhv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models"
      ],
      "metadata": {
        "id": "mNJOTyGHqJQg"
      },
      "id": "mNJOTyGHqJQg"
    },
    {
      "cell_type": "code",
      "source": [
        "class BertMeanClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, freeze_bert=False):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        # BERT outputs all hidden states\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        # The BERT model returns:\n",
        "        # - last_hidden_state: (batch_size, seq_len, hidden_dim)\n",
        "        # - pooler_output: (batch_size, hidden_dim)\n",
        "        last_hidden_state = outputs.last_hidden_state # (batch_size, seq_len, hidden_dim)\n",
        "        pooled_output = outputs.pooler_output  # [CLS] embedding after tanh layer\n",
        "\n",
        "        # Apply dropout + classification on the pooled [CLS] representation\n",
        "        out = self.classifier(self.dropout(pooled_output))\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "YCm7SwBiqODZ"
      },
      "id": "YCm7SwBiqODZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}